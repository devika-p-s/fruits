PYTHON PROGRAMS

def factorial(n):
    if n==0:
        return 1
    else:
        return n*factorial(n-1)
for x in range(11):
    print("factorial of",x,"is",factorial(x))



import random
MAX_LEN=int(input("Enter the length of the password:"))
strg_pwd=" "
pwd=['0','1','2','3','4','5','6','7','8','9',
    'a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z',
    'A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z',
    '@','#','$','%','=',':','?','.','/','|','~','>','*','(',')','<']
for x in range(MAX_LEN):
    strg_pwd=strg_pwd+random.choice(pwd)
print(strg_pwd)



NUMPY

import numpy as np
arr=np.array([[1,2,3],[3,2,1],[5,4,2]])
print('Array:\n',arr)
print('Array data type:',arr.dtype)
print('Array shape:',arr.shape)
print('Array size:',arr.size)
print('Array dimension:',arr.ndim)
print('Array item size:',arr.itemsize)


import numpy as np
arr=np.array([[1,2,3,4,5],[6,7,8,9,10]])
print('2nd element on 1st row:',arr[0,1])
print('5th element on 2nd row:',arr[1,4])
print('Slicing method:',arr[:,4])
print('Slicing method:',arr[1,:])


import numpy as np
arr=np.array([3,2,0,1])
print(np.sort(arr))
arr=np.array(['banana','cherry','apple'])
print(np.sort(arr))

import numpy as np
A=np.array([[1,2,3],[4,5,6]])
B=np.array([[1,2,3],[4,5,6]])
add=A+B
sub=A-B
mul=A*B
div=A/B
print('Addition:\n',add)
print('Substraction:\n',sub)
print('Multiplication:\n',mul)
print('Division:\n',div)


PANDAS

import pandas as pd
import numpy as np
info=np.array(['P','y','t','h','o','n'])
a=pd.Series(info)
print(a)
i=pd.Series(info,index=[100,101,102,103,104,105])
print(i)
print("Accessing pandas series element:")
print(i[100],'\t',a[0])


import pandas as pd
df=pd.read_csv(r"C:\Users\devik\Downloads\iris_data.csv")
print(df.to_string())


import pandas as pd
df=pd.read_csv(r"C:\Users\devik\Downloads\iris_data.csv")
print("Accessing 1st five rows")
print(df.head())
print("\nAccessing last five rows")
print(df.tail())
print("\nAccessing sepal length column")
print(df['sepal_length'])


import pandas as pd
df=pd.read_csv(r"C:\Users\devik\Downloads\iris_data.csv")
row1=df.loc[3]
print("Accessing using loc method:\n",row1)
row2=df.loc[3]
print("Accessing using loc method:\n",row2)



import pandas as pd
data1={'Name':['Arjun','Bhargav','Chetan','Das'],
       'Age':[27,24,22,32],
       'Address':['Davangere','Bagalkot','Hubballi','Mysore'],
       'Qualification':['BE','Mtech','MCA','Phd']}

data2={'Name':['Anjali','Bhagya','Chaya','Lata'],
       'Age':[17,14,12,52],
       'Address':['Bengalore','Mandya','Bellary','Gadag'],
       'Qualification':['Btech','BA','Bcom','Bhons']}
df=pd.DataFrame(data1,index=[0,1,2,3])
df1=pd.DataFrame(data2,index=[4,5,6,7])
print(df,"\n\n",df1)
print()

frames=[df,df1]
res1=pd.concat(frames)
print(res1)


MATPLOTLIB

import matplotlib.pyplot as plt
x=[1,1,3,3,5,5]
y=[0,4,1,1,4,0]
plt.plot(x,y,'r-o')
plt.xlabel('x-axis')
plt.ylabel('y-axis')
plt.title('Line graph')
plt.show()


import matplotlib.pyplot as plt
plt.bar([1,3,5],[5,4,3],label='one')
plt.bar([0,2,4],[3,4,5],label='two')
plt.legend()
plt.xlabel('Number')
plt.ylabel('Height')
plt.title('Bar graph')
plt.show()


import matplotlib.pyplot as plt
x=[2,2,2,3,4,5,6,6,6]
y=[1,2,3,2,1,2,3,2,1]
plt.scatter(x,y,label='scatskit')
plt.xlabel('x-axis')
plt.ylabel('y-axis')
plt.title('Scatter plot')
plt.legend()
plt.show()


import matplotlib.pyplot as plt
import numpy as np
x=np.random.normal(170,10,250)
plt.hist(x)
plt.grid()
plt.xlabel('x-axis')
plt.ylabel('y-axis')
plt.title('Histogram graph')
plt.show()


import matplotlib.pyplot as plt
import numpy as np
np.random.seed(10)
data_1=np.random.normal(100,10,200)
data_2=np.random.normal(90,20,200)
data_3=np.random.normal(80,30,200)
data=[data_1,data_2,data_3]
fig=plt.figure(figsize=(10,7))
ax=fig.add_axes([0,0,1,1])
bp=ax.boxplot(data)
plt.show()




SIMPLE LINEAR REGRESSION

import pandas as pd
df=pd.read_csv(r"C:\Users\devik\Downloads\iris_data.csv")
df.head()

print(df.shape)
print(df.info())

x=df[['sepal_length']]
y=df['sepal_width']
from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)

from sklearn.linear_model import LinearRegression
model=LinearRegression()
model.fit(x_train,y_train)

predictions=model.predict(x_test)
import sklearn.metrics as sm
print("Mean squared error=",round(sm.mean_squared_error(y_test,predictions),2))
print("R2 score=",round(sm.r2_score(y_test,predictions),2))





MULTIPLE LINEAR REGRESSION

import pandas as pd
df=pd.read_csv(r"C:\Users\devik\Downloads\iris_data.csv")
df.head()

print(df.shape)
print(df.info())

x=df[['petal_length','petal_width']]
y=df['sepal_length']
from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)

from sklearn.linear_model import LinearRegression
model=LinearRegression()
model.fit(x_train,y_train)

predictions=model.predict(x_test)
import sklearn.metrics as sm
print("Mean squared error=",round(sm.mean_squared_error(y_test,predictions),2))
print("R2 score=",round(sm.r2_score(y_test,predictions),2))





KNN Algorithm

import pandas as pd
df=pd.read_csv(r"C:\Users\devik\Downloads\iris_data.csv")
df.head()

print(df.shape)
print(df.info())

x=df.iloc[:,:-1].values
y=df.iloc[:,-1].values
from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)

from sklearn.neighbors import KNeighborsClassifier
knn=KNeighborsClassifier(n_neighbors=5,metric="euclidean")
knn.fit(x_train,y_train)
predictions=knn.predict(x_test)

from sklearn.metrics import confusion_matrix,accuracy_score
print(confusion_matrix(y_test,predictions))
print(accuracy_score(y_test,predictions))





DECISION TREE Algorithm

from sklearn.tree import DecisionTreeClassifier
clf=DecisionTreeClassifier(criterion='entropy',random_state=0)
clf.fit(x_train,y_train)
predictions=clf.predict(x_test)



NAIVE BAYES Algorithm

from sklearn.naive_bayes import GaussianNB
clf=GaussianNB()
clf.fit(x_train,y_train)
predictions=clf.predict(x_test)



LOGISTIC REGRESSION

from sklearn.linear_model import LogisticRegression
clf=LogisticRegression(random_state=0)
clf.fit(x_train,y_train)
predictions=clf.predict(x_test)



SVM

from sklearn.svm import SVC
clf=SVC(kernel='linear')
clf.fit(x_train,y_train)
predictions=clf.predict(x_test)





DATA PRE-PROCESSING

import pandas as pd
import numpy as np
df=pd.read_csv(r"C:\Users\devik\Downloads\iris_data.csv")
df

df.isnull().sum()
df.species.unique()

df=pd.get_dummies(df,columns=['species'])
df

from sklearn.preprocessing import LabelEncoder
LE=LabelEncoder()
df['species']=LE.fit_transform(df.species)
df

from pandas.io.formats.info import DataFrameInfo
from sklearn.preprocessing import StandardScaler
ss=StandardScaler()
df[['sepal_length','sepal_width']]=ss.fit_transform(df[['sepal_length','sepal_width']])
df





DEEP LEARNING

BOTSON HOUSING PRICE

import numpy as np
import keras
from keras.models import Sequential
from keras.layers import Dense

input2=np.array([1,2,3,4,5,6])
output2=np.array([4,5,6,7,8,9])
print(input2,output2)

model=Sequential()
model.add(Dense(units=1,input_shape=[1]))
model.compile(optimizer='sgd',loss='mean_squared_error')
model.summary()

model.fit(input2,output2,epochs=5)
model.predict([3])
model.weights



PIMA INDIANS DIABETES


from numpy import loadtxt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

df=loadtxt(r'C:\Users\devik\Downloads\pima-indians-diabetes.csv',delimiter=',')

x=df[:,0:8]
y=df[:,8]

model=Sequential()
model.add(Dense(12,input_shape=(8,),activation='relu'))
model.add(Dense(8,activation='relu'))
model.add(Dense(1,activation='sigmoid'))

model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])
model.fit(x,y,epochs=150,batch_size=10)

_,accuracy=model.evaluate(x,y)
print('Accuracy:%2f' %(accuracy*100))





WORD-CLOUD

import matplotlib.pyplot as plt
from wordcloud import WordCloud
Text="""Hi Mallesh where is Abeyaantrix, Mallesh replied as,Abeyaantrix softlab is in Davangere,Davangere is in Karnataka"""
WC=WordCloud().generate(Text)
plt.imshow(WC)
plt.axis('off')
plt.show()


PUNCTUATION

Text="""Hi Mallesh where is Abeyaantrix, Mallesh replied as,Abeyaantrix softlab is in Davangere,Davangere is in Karnataka!"""
import string
print('list of punctuations=\n\n',string.punctuation)
S=string.punctuation

Text_Punct=" ".join(item for item in Text.split() if item not in S )
print(Text)
print()
print('--------------text after removing punctuation---------------')
print()
print(Text_Punct)


STOP WORDS

import nltk
nltk.download('stopwords')

Text="""Hi Mallesh where is Abeyaantrix?, Mallesh replied as,Abeyaantrix softlab is in Davangere,Davangere is in Karnataka!"""
import nltk
from nltk.corpus import stopwords
stop_words=nltk.corpus.stopwords.words('english')
print(stop_words)

Text_Stop=" ".join(item for item in Text.split() if item not in stop_words)
print(Text)
print()
print('--------------text after removing stopwords---------------')
print()
print(Text_Stop)


STEMMING

import nltk
nltk.download('punkt')

Text="""You look smart,he looks like star,you are looking awesome"""
import nltk
from nltk.tokenize import word_tokenize
from nltk.stem import *
tokens=word_tokenize(Text)
print(tokens)

stemmer=nltk.stem.PorterStemmer()
T_stem=" ".join([stemmer.stem(item) for item in tokens])
T_stem


LEMMATIZATION

Text="""You look smart,he looks like star,you are looking awesome"""
import nltk
from nltk.tokenize import word_tokenize
nltk.download('wordnet')
nltk.download('omw-1.4')
nltk.download('punkt')
tokens=word_tokenize(Text)
print(tokens)

from nltk.stem.wordnet import WordNetLemmatizer
Lemma=nltk.stem.WordNetLemmatizer()
T_stem=" ".join([Lemma.lemmatize(item) for item in tokens])
T_stem











